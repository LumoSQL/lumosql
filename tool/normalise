#!/usr/bin/perl -w

# "normalise" test results by:
# 1. read all the html files specified on the command line
# 2. divide each number by the maximum for the results in the same test
#    (so the slowest will have 1.0000 etc)
# 3. print the result with 1 column per HTML file and 1 row per test
#
# example:
# make LMDB_0.9.24.html SQLite-3.7.17.html
# perl tool/normalise LMDB_0.9.24.html SQLite-3.7.17.html
# will compare the test results for SQLite+LMDB 0.9.24 and the unmodified SQLite

use strict;

my %lines = ();
my %cols = ();
for my $f (@ARGV) {
    $lines{$f} = [ ];
    $cols{$f} = length $f;
    open(F, '<', $f) or die "$f: $!\n";
    my $n = 0;
    while (<F>) {
	/^<tr><td>/ or next;
	/&nbsp;(\d+\.\d+)<\/td/ or next;
	my $n = $1;
	push @{$lines{$f}}, $n;
	$n = int($n + 0.5) + 5;
	$cols{$f} < length($n) and $cols{$f} = length($n);
    }
    close F;
}

my $fmt = join('  ', map { "\%$cols{$_}s" } @ARGV) . "\n";

printf $fmt, @ARGV;

while (@{$lines{$ARGV[0]}}) {
    my @data = map { shift @{$lines{$_}} } @ARGV;
    my $max = 0;
    for my $d (@data) {
	$d > $max and $max = $d;
    }
    @data = map { sprintf "%.4f", $_ / $max } @data;
    printf $fmt, @data;
}

