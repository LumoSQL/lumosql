<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Benchmarking</title>
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="1.1-front-page.html"><strong aria-hidden="true">1.</strong> Welcome</a></li><li class="chapter-item expanded "><a href="about.html"><strong aria-hidden="true">2.</strong> About LumoSQL</a></li><li class="chapter-item expanded "><a href="1.2-top-features.html"><strong aria-hidden="true">3.</strong> Top Features</a></li><li class="chapter-item expanded "><a href="1.4-install-LumoSQL.html"><strong aria-hidden="true">4.</strong> Install</a></li><li class="chapter-item expanded "><a href="quickstart.html"><strong aria-hidden="true">5.</strong> Quick Build and Benchmark</a></li><li class="chapter-item expanded affix "><li class="part-title">Features</li><li class="chapter-item expanded "><a href="3.4-not-forking-tool.html"><strong aria-hidden="true">6.</strong> Not-Forking Tool</a></li><li class="chapter-item expanded "><a href="lumo-build-benchmark.html"><strong aria-hidden="true">7.</strong> Build and Benchmark System (build.tcl)</a></li><li class="chapter-item expanded "><a href="backends.html"><strong aria-hidden="true">8.</strong> Available Backends - SQLite B-tree and LMDB</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="lumo-sqlite-bdb-backend.html"><strong aria-hidden="true">8.1.</strong> BDB 18.1.32 Backend</a></li><li class="chapter-item expanded "><a href="lumo-malbrain-backend.html"><strong aria-hidden="true">8.2.</strong> Karl Malbrain's C Btree</a></li></ol></li><li class="chapter-item expanded "><a href="lumo-corruption-detection-and-magic.html"><strong aria-hidden="true">9.</strong> Corruption Detection</a></li><li class="chapter-item expanded "><a href="3.3-benchmarking.html" class="active"><strong aria-hidden="true">10.</strong> Benchmarking</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="lumo-benchmark-filter.html"><strong aria-hidden="true">10.1.</strong> Displaying Benchmark Results (benchmark-filter.tcl)</a></li><li class="chapter-item expanded "><a href="statistical_analysis.html"><strong aria-hidden="true">10.2.</strong> Statistical Analysis</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">New features</li><li class="chapter-item expanded "><a href="rbac-design.html"><strong aria-hidden="true">11.</strong> Design of Role-Based Access Control</a></li><li class="chapter-item expanded "><a href="encryption.html"><strong aria-hidden="true">12.</strong> Encryption</a></li><li class="chapter-item expanded "><a href="lumion_intro.html"><strong aria-hidden="true">13.</strong> Lumion</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="rfc.html"><strong aria-hidden="true">13.1.</strong> Lumion RFC</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Research</li><li class="chapter-item expanded "><a href="2.1-development-landscape.html"><strong aria-hidden="true">14.</strong> SQLite Development Landscape</a></li><li class="chapter-item expanded "><a href="3.7-relevant-codebases.html"><strong aria-hidden="true">15.</strong> Overview of Relevant Codebases</a></li><li class="chapter-item expanded "><a href="2.4-relevant-knowledgebase.html"><strong aria-hidden="true">16.</strong> Overview of the Relevant Knowledgebase</a></li><li class="chapter-item expanded "><a href="3.6-development-notes.html"><strong aria-hidden="true">17.</strong> LumoSQL 2019 Prototype</a></li><li class="chapter-item expanded affix "><li class="part-title">Design</li><li class="chapter-item expanded "><a href="api.html"><strong aria-hidden="true">18.</strong> SQLite API Interception Points</a></li><li class="chapter-item expanded "><a href="virtual-machine.html"><strong aria-hidden="true">19.</strong> SQLite Virtual Machine Layer</a></li><li class="chapter-item expanded "><a href="WALs.html"><strong aria-hidden="true">20.</strong> LMDB Alternative to WALs</a></li><li class="chapter-item expanded "><a href="what-are-savepoints.html"><strong aria-hidden="true">21.</strong> Savepoints in SQLite</a></li><li class="chapter-item expanded "><a href="online-database-servers.html"><strong aria-hidden="true">22.</strong> Online Database Servers</a></li><li class="chapter-item expanded affix "><li class="part-title">Other</li><li class="chapter-item expanded "><a href="LumoSQL-PhaseII-Announce.html"><strong aria-hidden="true">23.</strong> News - Phase II Announcement</a></li><li class="chapter-item expanded "><a href="release-announce-0.4.html"><strong aria-hidden="true">24.</strong> News - Release 0.4 Announcement</a></li><li class="chapter-item expanded "><a href="release-announce-0.3.html"><strong aria-hidden="true">25.</strong> News - Release 0.3 Announcement</a></li><li class="chapter-item expanded "><a href="lumo-gsoc-ideas.html"><strong aria-hidden="true">26.</strong> Google Summer of Code 2021</a></li><li class="chapter-item expanded "><a href="lumo-proposed-debug.html"><strong aria-hidden="true">27.</strong> SQLite Debug Proposal</a></li><li class="chapter-item expanded "><a href="CONTRIBUTING.html"><strong aria-hidden="true">28.</strong> Conributing</a></li><li class="chapter-item expanded "><a href="lumosql-meetbot.html"><strong aria-hidden="true">29.</strong> Contributing - IRC Meetbot</a></li><li class="chapter-item expanded "><a href="CODE-OF-CONDUCT.html"><strong aria-hidden="true">30.</strong> Code of Conduct</a></li><li class="chapter-item expanded "><a href="3.2-legal-aspects.html"><strong aria-hidden="true">31.</strong> Legal Aspects</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="licensing.html"><strong aria-hidden="true">31.1.</strong> Licensing</a></li><li class="chapter-item expanded "><a href="MIT.html"><strong aria-hidden="true">31.2.</strong> MIT Licence</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <!-- SPDX-License-Identifier: CC-BY-SA-4.0 -->
<!-- SPDX-FileCopyrightText: 2020 The LumoSQL Authors -->
<!-- SPDX-ArtifactOfProjectName: LumoSQL -->
<!-- SPDX-FileType: Documentation -->
<!-- SPDX-FileComment: Original by Dan Shearer, 2020 -->
<h1 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h1>
<ul>
<li><a href="#about-benchmarking">About Benchmarking</a></li>
<li><a href="#all-sqlite-performance-papers-are-nonsense">All SQLite Performance Papers are Nonsense</a></li>
<li><a href="#limiting-the-problem-space">Limiting the Problem Space</a></li>
<li><a href="#what-questions-will-benchmarking-answer">What Questions Will Benchmarking Answer?</a></li>
<li><a href="#details-of-benchmarking-code">Details of Benchmarking Code</a>
<ul>
<li><a href="#metrics">Metrics</a></li>
<li><a href="#sql-in-benchmarktcl">SQL in benchmark.tcl</a></li>
<li><a href="#sql-logic-test">SQL Logic Test</a></li>
<li><a href="#c-speed-tests-with-sqlite-c-api">C speed tests with SQLite C API</a></li>
</ul>
</li>
<li><a href="#computer-architectures-and-operating-systems">Computer architectures and operating systems</a>
<ul>
<li><a href="#c-speed-tests-with-the-sqlitelumosql-kv-api">C speed tests with the SQLite/LumoSQL KV API</a></li>
</ul>
</li>
<li><a href="#list-of-relevant-benchmarking-and-test-knowledge">List of Relevant Benchmarking and Test Knowledge</a></li>
</ul>
<h1 id="about-benchmarkings"><a class="header" href="#about-benchmarkings">About Benchmarkings</a></h1>
<p>Having a reliable benchmarking system has always been one of the LumoSQL objectives. LumoSQL is a modification of SQLite and benchmarking is used to measure and compare the performance of different builds on different machines.</p>
<p>The results are stored in an SQLite database which is available to download at  <a href="https://lumosql.org/dist/benchmarks-to-date">https://lumosql.org/dist/benchmarks-to-date</a>. It is being actively updated and accepting data from volunteers. </p>
<blockquote>
<p><a href="https://lumosql.org/dist/benchmarks-to-date/all-lumosql-benchmark-data-combined.sqlite">Direct Download Link</a></p>
</blockquote>
<p>The source code for benchmarking tools can be found in the <a href="https://lumosql.org/src/lumosql/dir?name=tool">lumosql repo</a>. <em>benchmark-filter.tcl</em>  is a useful tool for viewing the data, see <a href="https://lumosql.org/src/lumosql/file?name=doc/lumo-benchmark-filter.md">documentation on how to use it</a>. </p>
<p>Alternatively, plotted data is presented with an <a href="http://r.lumosql.org:3838/contrastexample.html">interactive web UI</a>.</p>
<p>Once LumoSQL is installed the user can perform benchmarks using <code>make benchmark [OPTIONS]</code>. Follow an <a href="https://lumosql.org/src/lumosql/doc/tip/README.md#using-the-build-and-benchmark-system">example of running a benchmark</a> and read the full documantation on <a href="https://lumosql.org/src/lumosql/doc/tip/doc/lumo-build-benchmark.md">benchmark options</a>.</p>
<h1 id="discussion"><a class="header" href="#discussion">Discussion</a></h1>
<p>The strange thing is that benchmarking between SQL databases is almost non-existent, as well as difficult.
We focus on the practical recommendations of the 2018
paper <a href="https://mytherin.github.io/papers/2018-dbtest.pdf">Fair Benchmarking Considered Difficult:Common Pitfalls In Database Performance Testing</a>. 
We store the results in an SQLite database, and we make the method and the 
<a href="https://lumosql.org/dist/benchmarks-to-date/">results</a> available publicly.</p>
<p>The LumoSQL benchmarking problem is less difficult than comparing 
unrelated databases, which is perhaps why the <a href="https://tpc.org">Transaction Processing Performance Council</a> has not published news since 2004.
There are testing tools released with SQLite, Postgresql, MariaDB etc, but 
there simply is no way to compare. Benchmarking and testing overlap.</p>
<p>The well-described <a href="https://sqlite.org/testing.html">testing of SQLite</a>
involves some open code, some closed code, and many ad hoc processes. Clearly
the SQLite team have an internal culture of testing that has benefited the
world. However that is very different to testing that is reproducible by
anyone, which is in turn very different to reproducible reproducible by anyone,
and that is even without considering whether the benchmarking is a reasonable
approximation of actual use cases.</p>
<h2 id="all-sqlite-performance-papers-are-nonsense"><a class="header" href="#all-sqlite-performance-papers-are-nonsense">All SQLite Performance Papers are Nonsense</a></h2>
<p>In 2017 a helpful paper was published by <a href="https://www.cs.utexas.edu/%7Evijay/papers/apsys17-sqlite.pdf">Purohith, Mohan and Chidambaram</a> on the
topic of &quot;The Dangers and Complexities of SQLite Benchmarking&quot;. Since the first
potential problem is that this paper itself is in error, LumoSQL repeated
the literature research component in the paper. We agree with the authors in stating:</p>
<blockquote>
<p>When we investigated 16 papers from the 2015-2017
whose evaluation included SQLite, we find that none report
all the parameters required to meaningfully compare
results: ten papers do not report any parameters [17–26],
five do not report the sync mode [27–31], while only
one paper reports all parameters except write-ahead log
size [32]. Without reporting how SQLite was configured,
it is meaningless to compare SQLite results.</p>
</blockquote>
<p>LumoSQL found three additional papers published in 2017-2019, with similar flaws.
In brief:</p>
<blockquote>
<p><strong>All published papers on SQLite's performance are nonsense</strong></p>
</blockquote>
<p>And this is for SQLite alone, something that has relatively few parameters
compared to the popular online SQL databases. The field of SQL databases in
general is even more poorly benchmarked.</p>
<p>Benchmarking between SQL databases hardly exists at all. </p>
<h1 id="limiting-the-problem-space"><a class="header" href="#limiting-the-problem-space">Limiting the Problem Space</a></h1>
<p>LumoSQL has some advantages that reduce the problem space for benchmarking:</p>
<ul>
<li>The test harness is effectively the entire SQLite stack above the btree layer
(or lumo-backend.c). It is true that SQLite benchmarking is difficult because
there are so many pragmas and compile options, but most of these apply to all
backends. The <em>effect</em> of a given pragma or compile option may differ by
backend, but this will be a second-order effect and hopefully not as severe as
first-order effects.</li>
<li>The backends we have today differ in a relatively small number of dimensions,
usually to do with their speciality. The SQLite Btree backend has options for
WAL files, journals and cache sizes; the LMDB backend uses the OS buffer cache
and so there are OS-level defaults to be aware of; the BDB backend has tuning
options relating to cache and locking. That relatively small number of
differences still potentially gives a large benchmarking matrix, so we have to
control for that (or regard computation as free, which is close to accurate at
the scale of the LumoSQL project.)</li>
<li>No networking, clustering or client interoperability involved. This
eliminates many classes of complexity.</li>
</ul>
<p>To further reduce the problem space we will not be testing across multiple
platforms. This can be addressed later.</p>
<h1 id="what-questions-will-benchmarking-answer"><a class="header" href="#what-questions-will-benchmarking-answer">What Questions Will Benchmarking Answer?</a></h1>
<p>Questions by LumoSQL/SQLite internals developers:</p>
<ul>
<li>I am considering a change to the main code path to integrate a new feature,
will the performance of LumoSQL suffer?</li>
<li>I have identified a potential optimisation, is the performance benefit worth
the additional complexity?</li>
<li>I have implemented a new backend, should we make it the default?</li>
</ul>
<p>Questions by LumoSQL/SQLite application developers:</p>
<ul>
<li>Is LumoSQL any different from SQLite when configured to use the SQLite backend?</li>
<li>I have these requirements for a system, which LumoSQL backend should I choose?</li>
</ul>
<h1 id="checklist-from-the-considered-difficult-paper"><a class="header" href="#checklist-from-the-considered-difficult-paper">Checklist from the &quot;Considered Difficult&quot; Paper</a></h1>
<p>We have considered the checklist from the <a href="https://mytherin.github.io/papers/2018-dbtest.pdf">Fair Benchmarking Considered Difficult:Common Pitfalls In Database Performance Testing paper</a> as a guidline for good benckmarking practice.</p>
<ul>
<li>Choosing your Benchmarks.
<ul>
<li>Benchmark covers whole evaluation space</li>
<li>Justify picking benchmark subset</li>
<li>Benchmark stresses functionality in the evaluation space</li>
</ul>
</li>
<li>Reproduciblity.
<ul>
<li>Hardware configuration</li>
<li>DBMS parameters and version</li>
<li>Source code or binary files</li>
<li>Data, schema &amp; queries</li>
</ul>
</li>
<li>Optimization.
<ul>
<li>Compilation flags</li>
<li>System parameters</li>
</ul>
</li>
<li>Apples vs Apples
<ul>
<li>Similar functionality</li>
<li>Equivalent workload</li>
</ul>
</li>
<li>Comparable tuning
<ul>
<li>Different data</li>
<li>Various workloads</li>
</ul>
</li>
<li>Cold/warm/hot runs.
<ul>
<li>Differentiate between cold and hot runs</li>
<li>Cold runs: Flush OS and CPU caches</li>
<li>Hot runs: Ignore initial runs</li>
</ul>
</li>
<li>Preprocessing.
<ul>
<li>Ensure preprocessing is the same between systems</li>
<li>Be aware of automatic index creation</li>
</ul>
</li>
<li>Ensure correctness.
<ul>
<li>Verify results</li>
<li>Test different data sets</li>
<li>Corner cases work</li>
</ul>
</li>
<li>Collecting Results.
<ul>
<li>Do several runs to reduce interference</li>
<li>Check standard deviation for multiple runs</li>
<li>Report robust metrics (e.g., median and confidence inter-vals)</li>
</ul>
</li>
</ul>
<h2 id="reproducibility-and-tests"><a class="header" href="#reproducibility-and-tests">Reproducibility and Tests</a></h2>
<p>We aim to record a complete set of parameters that define the outcome of the benchmark run. First, to define the environment in which the runs are performed we record:</p>
<ul>
<li>os-type</li>
<li>os-version</li>
<li>cpu-type</li>
<li>cpu-comment</li>
<li>disk-comment</li>
<li>byte-order</li>
<li>word-size</li>
</ul>
<p>Secondly, the exact versions of software involved in the build process:</p>
<ul>
<li>backend</li>
<li>backend-id</li>
<li>backend-name</li>
<li>backend-version</li>
<li>backend-date</li>
<li>sqlite-id</li>
<li>sqlite-name</li>
<li>sqlite-version</li>
<li>sqlite-date</li>
<li>notforking-id</li>
<li>notforking-date</li>
</ul>
<p>And lastly, the software specific parameters:</p>
<ul>
<li>option-debug</li>
<li>option-lmdb_debug</li>
<li>option-lmdb_fixed_rowid</li>
<li>option-lmdb_transaction</li>
<li>option-rowsum</li>
<li>option-rowsum_algorithm</li>
<li>option-sqlite3_journal</li>
</ul>
<p>Each run performs 17 types of queries that reflect the average user experience (user-cpu-time,  system-cpu-time, and real-time is recorded for each test) :</p>
<ul>
<li>Creating database and tables</li>
<li>1000 INSERTs</li>
<li>100 UPDATEs without an index, upgrading a read-only transaction</li>
<li>25000 INSERTs in a transaction</li>
<li>100 SELECTs without an index</li>
<li>100 SELECTs on a string comparison</li>
<li>Creating an index</li>
<li>5000 SELECTs with an index</li>
<li>1000 UPDATEs without an index</li>
<li>25000 UPDATEs with an index</li>
<li>25000 text UPDATEs with an index</li>
<li>INSERTs from a SELECT</li>
<li>DELETE without an index</li>
<li>DELETE with an index</li>
<li>A big INSERT after a big DELETE</li>
<li>A big DELETE followed by many small INSERTs</li>
<li>DROP TABLE</li>
</ul>
<p>Runs are performed on different scales by multiplying the number of queries by some factor. That factor is recorded as:</p>
<ul>
<li>option-datasize</li>
</ul>
<h1 id="details-of-benchmarking-code"><a class="header" href="#details-of-benchmarking-code">Details of Benchmarking Code</a></h1>
<h2 id="metrics"><a class="header" href="#metrics">Metrics</a></h2>
<p>Benchmarking will take place via SQL, with these items being measured at least:</p>
<ul>
<li>
<p>Elapsed time for a series of SQL statements</p>
<p>The TCL script benchmark.tcl is a forked version of speedtest.tcl, which 
writes results to an SQLite database as well a producing HTML output.
The SQL statements are discussed further down in this section. Each of the 
timed tests will also have VDBE ops and IOPS recorded as per the next 
two sections.</p>
</li>
<li>
<p>VDBE Operations per second </p>
<p>benchmark.tcl can collect VDBE ops, but only with some help from LumoSQL.</p>
<p>A timer is started in sqlite3_prepare(), VDBE opcodes are counted in
sqlite3VdbeExec(), and the timer is stopped in sqlite3_finalize(). This
then allows us to calculate how long the sql3_stmt took to execute per
instruction. The number of instructions will be the same for all backends.</p>
</li>
<li>
<p>Disk Operations per second</p>
<p>benchmark.tcl can do this by comparing per-pid IOPS using the algorithm
here: https://github.com/true/aspersa-mirror/blob/master/iodump . 
We look up the IOPS at the beginning and end of the test and store the 
difference. </p>
<p>This is not portable to other operating systems, however, that will
hopefully be a relatively small variable compared to the the 
variable of one backend vs another. </p>
</li>
</ul>
<h2 id="sql-in-benchmarktcl"><a class="header" href="#sql-in-benchmarktcl">SQL in benchmark.tcl</a></h2>
<p>To start with we are modifying speedtest.tcl as described. We are adding a BLOB
test with large generated blobs, but it is basically the same. In the future we
need to have more realistic SQL statements. And that varies by use case:</p>
<ol>
<li>embedded style SQL statements, typically developing for heavily resource
constrained deployments, who are likely to use SQL to simply store and
retrieve values and be more interested in tradeoffs and settings that
reduce latency. Tightly coupled with the SQLite library. Short transactions.</li>
<li>online style SQL statements, used for transaction processing. Concurrency
matters. Same SQL might be used with another database. Some long transactions.</li>
<li>online style SQL statements, used for analytics processing. Much more 
batch oriented. Same SQL might be used with another database. Some long transactions.</li>
</ol>
<h2 id="sql-logic-test"><a class="header" href="#sql-logic-test">SQL Logic Test</a></h2>
<p>It isn't clear that the SQL logic test is suitable for benchmarking. We are 
working on this, but our hope is that it will be readily adaptable.</p>
<p>This works by ODBC - noting that SQLite has an ODBC driver.</p>
<h2 id="c-speed-tests-with-sqlite-c-api"><a class="header" href="#c-speed-tests-with-sqlite-c-api">C speed tests with SQLite C API</a></h2>
<p>We have only done basic testing to make sure the code runs.  Our objective in
running these tests will be to quantify performance. These tests use the C API.</p>
<p><code>speedtest1.c</code> appears to be very actively maintained by <a href="https://sqlite.org">https://sqlite.org</a>,
the file has a number of different contributors and has frequent commits.</p>
<p><code>mptest.c</code> and <code>threadtest3.c</code> look promising for testing async access. See the 
notes previously about the unsophisticated concurrency handling we have already
demonstrated in SQLite. </p>
<h1 id="computer-architectures-and-operating-systems"><a class="header" href="#computer-architectures-and-operating-systems">Computer architectures and operating systems</a></h1>
<p>We are not going to get ambitious with platforms and variations. For the present,
benchmarking on 64 bit x86 Linux will be sufficient.</p>
<p>We will impose memory pressure in benchmarking runs by limiting the memory
available to the LumoSQL process. However we can do this effectively with the
cgroups API rather than having small VMs.</p>
<p>Other obvious variations for the future include Windows, and 32-bit hardware.
We are ignoring these for now.</p>
<h2 id="c-speed-tests-with-the-sqlitelumosql-kv-api"><a class="header" href="#c-speed-tests-with-the-sqlitelumosql-kv-api">C speed tests with the SQLite/LumoSQL KV API</a></h2>
<p>This is a lesser priority.</p>
<p>It is important to also benchmark at the LumoSQL KV API level, ie
lumo-backend.c .  This is so that we can observe if the performance of each
backend remains roughly the same (especially, <em>relatively</em> the same compared to
the others) whether accessed via the SQLite API or directly via the common KV
API. It is possible that the SQLite stack will have some unexpected interaction
with a particular backend - to pick a pathological corner case, a magic string.</p>
<h1 id="list-of-relevant-benchmarking-and-test-knowledge"><a class="header" href="#list-of-relevant-benchmarking-and-test-knowledge">List of Relevant Benchmarking and Test Knowledge</a></h1>
<p>References articles and papers discussing benchmarking can be found in the <a href="./2.4-relevant-knowledgebase.html#list-of-relevant-benchmarking-and-test-knowledge">Full Knowledgebase Relevant to LumoSQL</a> section.</p>
<p>References to other benchmarking tools are linked in the <a href="./3.7-relevant-codebases.html">Relevant Codebases</a> section.</p>
<h1 id="benchmarking-lumosql"><a class="header" href="#benchmarking-lumosql">Benchmarking LumoSQL</a></h1>
<h1 id="nature-of-the-benchmarking"><a class="header" href="#nature-of-the-benchmarking">Nature of the Benchmarking</a></h1>
<p>The SQL benchmarking is to seek answers about throughput:</p>
<ul>
<li>total time elapsed for tests</li>
<li>bytes per second (in cases where we are reading or writing a known quantity of data)</li>
<li>operations per second (with the ops measured either by <em>vdbe</em>c, or os_*c, or both.) </li>
</ul>
<p>LumoSQL benchmarking will mostly be using blackbox testing approaches
(high-level functionality) with some highly-targetted whitebox testing for
known tricky differences between backends (eg locking). </p>
<p>Being a low-level library, functional benchmarking often gets close to
internals testing. That's ok, but we need to be aware of this. We don't want to
be doing internals testing. That is for make test.</p>
<p>At a later date we can add benchmarking at LumoSQL KV API level, ie
lumo-backend.c .  This is so that we can observe if the performance of each
backend remains roughly the same (especially, <em>relatively</em> the same compared to
the others) whether accessed via the SQLite API or directly via the common KV
API. It is possible that the SQLite stack will have some unexpected interaction
with a particular backend - to pick a pathological corner case, a magic string.</p>
<h1 id="possible-benchmarking-dimensions"><a class="header" href="#possible-benchmarking-dimensions">Possible Benchmarking Dimensions</a></h1>
<p>[TBD - notes only]</p>
<ul>
<li>Dataset can fit entirely in memory (or not)</li>
<li>Caching (durability on/off)</li>
<li>Updates vs Reads vs -Only</li>
<li>Ops per second at disk</li>
<li>VDBE ops per second</li>
<li>Latency at C API</li>
<li>Blobs</li>
</ul>
<h1 id="sql-dimensions"><a class="header" href="#sql-dimensions">SQL Dimensions</a></h1>
<ul>
<li>Single filtering plus offset</li>
<li>join with grouping and ordering</li>
<li>multiple indexing</li>
</ul>
<h1 id="concurrency-dimensions"><a class="header" href="#concurrency-dimensions">Concurrency Dimensions</a></h1>
<p>This is going to be very important, especially since concurrency is one of SQLite known weak points.
<a href="https://github.com/sqlite/sqlite/blob/master/test/async2.test">The async SQLite tests</a> don't seem to be stressing concurrency really.
<a href="https://github.com/sqlite/sqlite/tree/master/mptest">mptest</a> seems to be more along those lines but I haven't done sample runs of it (mptest hasn't changed in 7 years, and all the references to it seem to be in the context of Windows, if that means anything.)</p>
<h1 id="workload-simulation"><a class="header" href="#workload-simulation">Workload Simulation</a></h1>
<ul>
<li>Analytics-type workload patterns</li>
<li>Human thread-following app simulation - nearly all read operations</li>
<li>50/50 read/write - classical ecommerce-type application</li>
<li>Mixture of all of above on different threads to be really mean</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                                                    <a rel="prev" href="lumo-corruption-detection-and-magic.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        
                                                    <a rel="next" href="lumo-benchmark-filter.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                                    <a rel="prev" href="lumo-corruption-detection-and-magic.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                
                                    <a rel="next" href="lumo-benchmark-filter.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
        
    </body>
</html>
